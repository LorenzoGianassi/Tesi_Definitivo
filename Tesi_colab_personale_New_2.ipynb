{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tesi_colab_personale_New_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oelqpO_EUVOt",
        "outputId": "83e2d771-4659-4dd9-915a-4ddc85909a58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "from itertools import islice\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from torch.optim import SGD\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import MNIST\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from timeit import default_timer as timer\n",
        "from torch.utils.data import Subset\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import copy\n",
        "from torch.backends import cudnn\n",
        "import pandas as pd\n",
        "\n",
        "# associo cuda per lavorare ulla gpu\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(device)\n",
        "                #####################################################################################\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "\n",
        "                #####################################################################################\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self,numFC2=84):\n",
        "      super(Net, self).__init__()\n",
        "      self.numFC2 = numFC2\n",
        "      self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "      self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "      self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "      self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "      self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "      self.conv5 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "      self.conv6 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "      self.fc1 = nn.Linear(256*8*8, 120)\n",
        "      self.fc2 = nn.Linear(120, numFC2)\n",
        "      self.task_fcs = []       # Will hold all Linear layers for classification heads.\n",
        "      self.current_tasks = []  # Selects which task(s) are currently active.\n",
        "      self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x =(F.relu(self.conv1(x)))\n",
        "    x =(F.relu(self.conv2(x)))\n",
        "    x =(F.relu(self.conv3(x)))\n",
        "    x = self.pool(x)\n",
        "    x =(F.relu(self.conv4(x)))\n",
        "    x =(F.relu(self.conv5(x)))\n",
        "    x =(F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "    x = x.view(-1, 256*8*8)\n",
        "    x = self.dropout(F.relu(self.fc1(x)))\n",
        "    x = self.dropout (F.relu(self.fc2(x)))\n",
        "    # Concatenates the classification heads of selected tasks.\n",
        "    #outputs = torch.cat([F.log_softmax(self.task_fcs[t](x)) for t in self.current_tasks], 1)\n",
        "    outputs = torch.cat([(self.task_fcs[t](x)) for t in self.current_tasks], 1)\n",
        "    return outputs\n",
        "\n",
        "\n",
        "  # Add a new classification head with num_classes outputs.\n",
        "  def add_task(self, num_classes):\n",
        "      fc = nn.Linear(self.numFC2, num_classes)\n",
        "      self.add_module(name=f'task{len(self.task_fcs)}_fc', module=fc)\n",
        "      #self.add_module(name=str(len(self.task_fcs)), module=fc)\n",
        "      self.task_fcs.append(fc)\n",
        "\n",
        "  # Set the current task(s) -- takes a *LIST* of task ids.\n",
        "  def set_tasks(self, tasks):\n",
        "      self.current_tasks = tasks\n",
        "\n",
        "\n",
        "                                         ###########################################################################\n",
        "\n",
        "# CLASSE IL DATASET FILTRATO\n",
        "class Filtered_Dataset(Dataset): \n",
        "  def __init__(self, dataset, indices, offset=0):\n",
        "        self.indices = indices # indici dei target di cui ci interessa il target\n",
        "        self.original_indices = [i for i in range(len(dataset.targets)) if dataset.targets[i] in indices] # filtraggio degli indici del dataset che voglio nel subset\n",
        "        self.dataset = Subset(dataset, self.original_indices)\n",
        "        #self.original2task = { indices[i]  : offset + i for i in range(0,  len(indices) ) } # remapping degli indici con chiavi i valori degli indici del del task\n",
        "        self.original2task = self.dictmap(indices,offset)\n",
        "        self.task2original = dict({ (val, key) for (key, val) in self.original2task.items() }) # remapping degli indici con chiavi i valori degli indici del del task\n",
        "        \n",
        "  def __getitem__(self, idx):\n",
        "        (x, y) = self.dataset[idx]\n",
        "        return (x, self.original2task[y])\n",
        "\n",
        "  def __len__(self):\n",
        "        return len(self.original_indices)\n",
        "\n",
        "  def dictmap(self,indices,offset):\n",
        "      original2task={}\n",
        "      idx = np.arange(len(indices))\n",
        "      idx_tmp = np.arange(len(indices))\n",
        "      for i in range(0,len(idx)):\n",
        "        if (idx[i]+offset) in indices:\n",
        "          original2task[idx[i]+offset] = (idx[i] + offset)\n",
        "          indices  = np.delete(indices, np.argwhere(indices == (idx[i]+offset)))\n",
        "          idx_tmp  = np.delete(idx_tmp,np.argwhere(idx_tmp == (idx[i])))     \n",
        "      for i in range(0,len(indices)):\n",
        "          original2task[indices[i]]=idx_tmp[i] + offset   \n",
        "      return original2task\n",
        "\n",
        "\n",
        "                                          ###########################################################################\n",
        "\n",
        "# METODO PER SPLITTARE GLI INDICI DEI TARGET DEL TRAINSET/TESTSET\n",
        "def idx_tasks(num_tasks,trainset,rand=True):   # genero un np array e splitto in task\n",
        "  targets = np.unique(trainset.targets)\n",
        "  tasks = []\n",
        "  if rand:\n",
        "    unique_targets = np.random.permutation(len(targets))\n",
        "    tasks = np.split(unique_targets,num_tasks,axis=0)\n",
        "  else:  \n",
        "    tasks = np.split(targets,num_tasks,axis=0)\n",
        "  if num_tasks!=1 and rand:  \n",
        "    for i in range(0,len(tasks)):\n",
        "      tasks[i] = np.sort(tasks[i])\n",
        "  return tasks # ritorno gli indici per poi usare nella funzione successiva\n",
        "\n",
        "                                   #####################################################################################\n",
        "\n",
        "# METODO CHE ESEGUE IL TRAIN DELLA RETE                                   \n",
        "def train(trainloader,optimizer,criterion,scheduler,net):\n",
        "    losses = []\n",
        "    for epoch in range(20):  # loop over the dataset multiple times\n",
        "        start = timer()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            labels = data[1]\n",
        "            inputs, labels = data[0].to(device), labels.to(device) \n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            #print(outputs.dtype)\n",
        "            loss = criterion(outputs, labels)\n",
        "            losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            optimizer.step() \n",
        "        mean_losses= sum(losses)/len(losses)\n",
        "        #scheduler.step(mean_losses)\n",
        "        end = timer()\n",
        "        print(\"Tempo dell'epoca \",epoch,\"uguale a: \", (end - start), \"sec\")\n",
        "    print('ALLENAMENTO FINITO')\n",
        "    print(\"################################\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzr2ji4lUh1d",
        "outputId": "22ae51a6-c44e-4cc4-8d8c-0a6d32438f7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "#device = \"cpu\"\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
        "\n",
        "ds_train = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                    download=True, transform=transform)\n",
        "ds_test = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                    download=True, transform=transform)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7iqXeB-H12i",
        "outputId": "af7d1ed4-935b-4aae-d772-a586c909e2c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "                    # NUOVI METODI IMPLEMENTATI: TEST GENERALE DELLA NET, TEST PER OGNI CLASSE, BACKBONE ROUTINE\n",
        "\n",
        "# METODO PER GENERARE I FILTERED DATASET CON L'OFFSET\n",
        "def task_dss(tasks,ds,offset_change=True): # aggiunto check su offset in modo tale da non cambaire offset ai task\n",
        "    task_dss = []\n",
        "    offset = 0\n",
        "    for tsk in tasks:\n",
        "      print(offset)\n",
        "      tmp = Filtered_Dataset(ds, tsk, offset)\n",
        "      task_dss.append(tmp)\n",
        "      if offset_change:\n",
        "          offset += len(tsk)\n",
        "      else :\n",
        "        offset = 0    \n",
        "    return task_dss  \n",
        "# METODO TASK SULLA RETE GENERALE    \n",
        "def test(testloader,net,task_dss,num_task):\n",
        "    # accuracy dell'intero network\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1) # torna il valore max della tupla\n",
        "            if num_task <= 1:\n",
        "              for keys in task_dss.task2original:\n",
        "                  predicted[predicted == keys]=task_dss.task2original[keys]\n",
        "                  labels[labels == keys]=task_dss.task2original[keys]  \n",
        "            else:\n",
        "              for task in task_dss:\n",
        "                for keys in task.task2original:\n",
        "                  predicted[predicted == keys]=task.task2original[keys]\n",
        "                  labels[labels == keys]=task.task2original[keys]         \n",
        "            total += labels.size(0)\n",
        "            #print(total)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            #print('corrette',correct)\n",
        "    net.train()\n",
        "    print('Accuracy of the network : %d %%' % (\n",
        "            100 * correct / total)) \n",
        "    return (100 * correct / total)\n",
        "\n",
        "# METODO PER CALCOLO ACCURACY DELE CLASSI    \n",
        "def test_class(testloader,net,task_dss,index,num_task):\n",
        "    class_correct = list(0. for i in range(10)) \n",
        "    class_total = list(0. for i in range(10))\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = net(images)\n",
        "            \n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            if num_task <= 1:\n",
        "              for keys in task_dss.task2original:\n",
        "                  predicted[predicted == keys]=task_dss.task2original[keys]\n",
        "                  labels[labels == keys]=task_dss.task2original[keys]  \n",
        "            else:\n",
        "              for task in task_dss:\n",
        "                for keys in task.task2original:\n",
        "                  predicted[predicted == keys]=task.task2original[keys]\n",
        "                  labels[labels == keys]=task.task2original[keys]    \n",
        "            c = (predicted == labels).squeeze()\n",
        "            for i in range(16):\n",
        "                label = labels[i]\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "                #print('valore class total ',class_total[label])\n",
        "    if num_task<=1:\n",
        "        for i in index:\n",
        "         print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))  \n",
        "    else:\n",
        "      for tsk in index:\n",
        "        for i in tsk:\n",
        "          print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))    \n",
        "    print(\"################################\")      \n",
        "\n",
        "# METODO PER ESEGUIRE IL CONTIUAL LEARNING TASK AGNOSTIC\n",
        "\n",
        "def continual_agnostic(net, tasks,task_train_dls,task_test_dls,task_test_dss): \n",
        "  tsk = [] # indici dei task incrementali \n",
        "  optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "  #optimizer = optim.Adam(net.parameters(), lr=0.0005)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  for i in range(0,len(tasks)):\n",
        "    print(net)\n",
        "    tsk.append(i)\n",
        "    net.add_task(len(tasks[i]))\n",
        "    net.set_tasks(tsk)\n",
        "    net.to(device)\n",
        "    net.train()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "    #optimizer = optim.Adam(net.parameters(), lr=0.0005)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    train(task_train_dls[i],optimizer,criterion,net)\n",
        "    if len(tsk)>1:\n",
        "      #net.set_tasks(tsk) # TASK AGNOSTIC, non so quale task sto eseguendo, output solo\n",
        "      #net.to(device)\n",
        "      for i in range (0,len(tsk)):\n",
        "        print(f'AFTER TRAINING TASKS : {tsk}')\n",
        "        print('TASK ',i)\n",
        "        acc =test(task_test_dls[i],net,task_test_dss[i],num_task=1)\n",
        "    else:    \n",
        "        net.set_tasks(tsk)\n",
        "        net.to(device)\n",
        "        acc = test(task_test_dls[i],net,task_test_dss[i],num_task=1)\n",
        "  return net    \n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "ds_train = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                    download=True, transform=transform)\n",
        "ds_test = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                    download=True, transform=transform)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqbpO2ajVW71"
      },
      "source": [
        "#METODO CHE PRINTA LE ACCURACY PRIMA E DOPO L'ULTIMO TASK CON TIPOLOGIA TASK_AGNOSTIC\n",
        "def continual_table_agnostic(tasks,task_train_dls,task_test_dls,task_test_dss): \n",
        "  tsk = [] # indici dei task incrementali\n",
        "  accuracies1 = []\n",
        "  accuracies2 = [] \n",
        "  net = Net()\n",
        "  for i in range(0,len(tasks)):\n",
        "    index = i\n",
        "    print(net)\n",
        "    tsk.append(i)\n",
        "    net.add_task(len(tasks[i]))\n",
        "    net.set_tasks(tsk)\n",
        "    net.to(device)\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.0005)\n",
        "    #optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=4,verbose=True)\n",
        "    train(task_train_dls[i],optimizer,criterion,scheduler,net)\n",
        "    print('TASK ',i)\n",
        "    acc = test(task_test_dls[i],net,task_test_dss[i],num_task=1)\n",
        "    accuracies1.append(acc)\n",
        "    if  index == (len(tasks)-1):\n",
        "      #net.set_tasks(tsk)\n",
        "      #net.to(device)\n",
        "      print(tsk)\n",
        "      for idx in range (0,len(tsk)):\n",
        "        acc_tmp = test(task_test_dls[idx],net,task_test_dss[idx],num_task=1)\n",
        "        accuracies2.append(acc_tmp)\n",
        "  df = pd.DataFrame()\n",
        "  df['first_training']=accuracies1\n",
        "  df['last_training']=accuracies2 \n",
        "  avg1 = np.average(df['first_training'])\n",
        "  avg2 = np.average(df['last_training']) \n",
        "  print(\"Accuracy Precedente:\",avg1,\"Accuracy Successiva:\",avg2)\n",
        "  forgetting= avg1-avg2\n",
        "  print(\"Forgetting:\",forgetting)         \n",
        "  return net,df,forgetting\n",
        "\n",
        "\n",
        "\n",
        "# METODO CHE PRINTA LE ACCURACY PRIMA E DOPO L'ULTIMO TASK CON TIPOLOGIA TASK_AWARE\n",
        "def continual_table_aware(tasks,task_train_dls,task_test_dls,task_test_dss): \n",
        "  tsk = [] # indici dei task incrementali\n",
        "  accuracies1 = []\n",
        "  accuracies2 = [] \n",
        "  net = Net()\n",
        "  for i in range(0,len(tasks)):\n",
        "    index = i\n",
        "    print(net)\n",
        "    tsk.append(i)\n",
        "    net.add_task(len(tasks[i]))\n",
        "    net.set_tasks([i])\n",
        "    net.to(device)\n",
        "    for child  in trained_net_agnostic.children():\n",
        "        last_layer = child\n",
        "    #optimizer = optim.SGD(last_layer.parameters(), lr=0.001, momentum=0.9)\n",
        "    optimizer = optim.Adam(last_layer.parameters(), lr=0.0005)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=4,verbose=True)\n",
        "    train(task_train_dls[i],optimizer,criterion,scheduler,net)\n",
        "    print('TASK ',i)\n",
        "    net.set_tasks([i])\n",
        "    net.to(device)\n",
        "    acc = test(task_test_dls[i],net,task_test_dss[i],num_task=1)\n",
        "    accuracies1.append(acc)\n",
        "    if  index == (len(tasks)-1):\n",
        "      for idx in range (0,len(tsk)):\n",
        "        print([idx])\n",
        "        net.set_tasks([idx])\n",
        "        net.to(device)\n",
        "        acc_tmp = test(task_test_dls[idx],net,task_test_dss[idx],num_task=1)\n",
        "        accuracies2.append(acc_tmp)\n",
        "  df = pd.DataFrame()\n",
        "  df['first_training']=accuracies1\n",
        "  df['last_training']=accuracies2   \n",
        "  avg1 = np.average(df['first_training'])\n",
        "  avg2 = np.average(df['last_training']) \n",
        "  print(\"Accuracy Precedente:\",avg1,\"Accuracy Successiva:\",avg2)\n",
        "  forgetting= avg1-avg2\n",
        "  print(\"Forgetting:\",forgetting)   \n",
        "  return net,df,forgetting  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdjq-YqaVYyy"
      },
      "source": [
        "task_join = idx_tasks(1,ds_train,rand=False)\n",
        "task_train_dss = task_dss(task_join, ds_train,offset_change=True) \n",
        "task_test_dss = task_dss(task_join, ds_test,offset_change=True) \n",
        "task_train_dls = [DataLoader(ds,batch_size=16,shuffle=True,num_workers=4) for ds in task_train_dss]\n",
        "task_test_dls = [DataLoader(ds, batch_size=16,shuffle=False,num_workers=4) for ds in task_test_dss]\n",
        "\n",
        "# JOINT-TRAIN\n",
        "print(task_join)\n",
        "trained_net_join,df_join,forgetting = continual_table_agnostic(task_join,task_train_dls,task_test_dls,task_test_dss)\n",
        "print(df_join)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqWz4tl9Vbys"
      },
      "source": [
        "def continual_table(tasks,task_train_dls,task_test_dls,task_test_dss,agnostic_train=True,agnsotic_test=True): \n",
        "  tsk = [] # indici dei task incrementali\n",
        "  accuracies1 = []\n",
        "  accuracies2 = [] \n",
        "  net = Net()\n",
        "  for i in range(0,len(tasks)):\n",
        "    index = i\n",
        "    print(net)\n",
        "    tsk.append(i)\n",
        "    net.add_task(len(tasks[i]))\n",
        "    if agnostic_train:\n",
        "       net.set_tasks(tsk)\n",
        "       net.to(device)\n",
        "       optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "       #optimizer = optim.Adam(net.parameters(), lr=0.0005)\n",
        "       criterion = nn.CrossEntropyLoss()\n",
        "       scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=4,verbose=True)\n",
        "       train(task_train_dls[i],optimizer,criterion,scheduler,net)\n",
        "       if agnsotic_test:\n",
        "         acc = test(task_test_dls[i],net,task_test_dss[i],num_task=1)\n",
        "         accuracies1.append(acc)\n",
        "       else:\n",
        "           net.set_tasks([i])  \n",
        "           net.to(device)  \n",
        "           acc = test(task_test_dls[i],net,task_test_dss[i],num_task=1)\n",
        "           accuracies1.append(acc)\n",
        "    else:\n",
        "      net.set_tasks([i])  \n",
        "      net.to(device) \n",
        "      optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "      #optimizer = optim.Adam(net.parameters(), lr=0.0005)\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "      scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=4,verbose=True)\n",
        "      train(task_train_dls[i],optimizer,criterion,scheduler,net)\n",
        "      if agnsotic_test:\n",
        "          net.set_tasks(tsk)\n",
        "          net.to(device)\n",
        "          acc = test(task_test_dls[i],net,task_test_dss[i],num_task=1)\n",
        "          accuracies1.append(acc)\n",
        "      else:\n",
        "          net.set_tasks([i])  \n",
        "          net.to(device)  \n",
        "          acc = test(task_test_dls[i],net,task_test_dss[i],num_task=1)\n",
        "          accuracies1.append(acc)\n",
        "    print('TASK ',i)\n",
        "    if  index == (len(tasks)-1):\n",
        "      if agnsotic_test:\n",
        "          net.set_tasks(tsk)\n",
        "          net.to(device)   \n",
        "          print(tsk)\n",
        "          for idx in range (0,len(tsk)):\n",
        "            acc_tmp = test(task_test_dls[idx],net,task_test_dss[idx],num_task=1)\n",
        "            accuracies2.append(acc_tmp)\n",
        "      else:\n",
        "          print(tsk)\n",
        "          for idx in range (0,len(tsk)):\n",
        "            net.set_tasks([idx])\n",
        "            net.to(device)   \n",
        "            acc_tmp = test(task_test_dls[idx],net,task_test_dss[idx],num_task=1)\n",
        "            accuracies2.append(acc_tmp)\n",
        "  df = pd.DataFrame()\n",
        "  df['first_training']=accuracies1\n",
        "  df['last_training']=accuracies2 \n",
        "  avg1 = np.average(df['first_training'])\n",
        "  avg2 = np.average(df['last_training']) \n",
        "  print(\"Accuracy Precedente:\",avg1,\"Accuracy Successiva:\",avg2)\n",
        "  forgetting= avg1-avg2\n",
        "  print(\"Forgetting:\",forgetting)         \n",
        "  return net,df,forgetting\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kXCmMzJVetR"
      },
      "source": [
        "#Training_Aware\n",
        "tasks = idx_tasks(5,ds_train,rand=False) \n",
        "task_train_dss = task_dss(tasks, ds_train,offset_change=False) \n",
        "task_test_dss = task_dss(tasks, ds_test,offset_change=False) \n",
        "task_train_dls = [DataLoader(ds,batch_size=16,shuffle=True,num_workers=4) for ds in task_train_dss]\n",
        "task_test_dls = [DataLoader(ds, batch_size=16,shuffle=False,num_workers=4) for ds in task_test_dss]\n",
        "\n",
        "trained_net_aware,df_table_aw_aw, forgetting= continual_table(tasks,task_train_dls,task_test_dls,task_test_dss,agnostic_train=False,agnsotic_test=False)\n",
        "trained_net_aware,df_table_aw_agn, forgetting= continual_table(tasks,task_train_dls,task_test_dls,task_test_dss,agnostic_train=False,agnsotic_test=True)\n",
        "print(df_table_aw_aw)\n",
        "print(df_table_aw_agn) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSjo9hJlVfdg"
      },
      "source": [
        "#Training_Agnostic\n",
        "tasks = idx_tasks(5,ds_train,rand=False) \n",
        "task_train_dss = task_dss(tasks, ds_train,offset_change=True) \n",
        "task_test_dss = task_dss(tasks, ds_test,offset_change=False) \n",
        "task_train_dls = [DataLoader(ds,batch_size=16,shuffle=True,num_workers=4) for ds in task_train_dss]\n",
        "task_test_dls = [DataLoader(ds, batch_size=16,shuffle=False,num_workers=4) for ds in task_test_dss]\n",
        "\n",
        "trained_net_agnostic,df_table_agn_agn,forgetting = continual_table(tasks,task_train_dls,task_test_dls,task_test_dss,agnostic_train=True,agnsotic_test=True)\n",
        "trained_net_agnostic,df_table_agn_aw,forgetting = continual_table(tasks,task_train_dls,task_test_dls,task_test_dss,agnostic_train=True,agnsotic_test=False)\n",
        "\n",
        "print(df_table_agn_agn) \n",
        "print(df_table_agn_aw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rS5dCdrVipk"
      },
      "source": [
        "print('AWARE')\n",
        "print(df_table_aw_aw.head())\n",
        "print(df_table_aw_agn.head()) \n",
        "print('AGNOSTIC')\n",
        "print(df_table_agn_agn.head()) \n",
        "print(df_table_agn_aw.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c6dDySiV-di"
      },
      "source": [
        "def plot_accuracies(df_agn,df_awa):\n",
        "  x = ['task 0', 'task 1', 'task 2', 'task 3', 'task 4']\n",
        "  y_joint = [77.6,77.6,77.6,77.6,77.6]\n",
        "  y_first_agnostic = df_agn.first_training\n",
        "  y_first_aware = df_awa.first_training\n",
        "  y_last_agnostic = df_agn.last_training\n",
        "  y_last_aware = df_awa.last_training\n",
        "  plt.plot(x,y_joint,label='joint train')\n",
        "  plt.plot(x,y_first_agnostic,color='b',marker='o',label='First train/Aware Test')\n",
        "  plt.plot(x,y_first_aware,color='r',marker='o',label='First train/Agnostic Test')\n",
        "  plt.plot(x,y_last_agnostic,color='b',linestyle='--',marker='o',label='Last train/Aware Test')\n",
        "  plt.plot(x,y_last_aware,color='r',linestyle='--',marker='o',label='Last train/Agnostic Test')\n",
        "  plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
        "  plt.xlabel('TASKS')\n",
        "  plt.ylabel('ACCURACIES')\n",
        "  plt.title('AGNOSTIC TRAINING')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5pwCTE3WBdu"
      },
      "source": [
        "plot_accuracies(df_table_aw_aw,df_table_aw_agn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4lkMbTaWD2B"
      },
      "source": [
        "plot_accuracies(df_table_agn_aw,df_table_agn_agn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA4sj1gP_Fee"
      },
      "source": [
        "# CLASSE IL DATASET FILTRATO\n",
        "class Filtered_Dataset_Replay(Dataset): \n",
        "  def __init__(self,dataset,indices,tasks,idx,offset=0,replay_num=100):\n",
        "        self.indices = indices # indici dei target di cui ci interessa il target\n",
        "        self.original_indices = [i for i in range(len(dataset.targets)) if dataset.targets[i] in indices] # filtraggio degli indici del dataset che voglio nel subset\n",
        "        if idx!=0:\n",
        "          for id in range(0,idx):\n",
        "           self.replay_indices = [i for i in range(len(dataset.targets)) if dataset.targets[i] in tasks[id]]\n",
        "           self.replay_indices = random.sample(self.replay_indices,replay_num)\n",
        "           self.original_indices = self.original_indices + self.replay_indices # concateno gli indici\n",
        "           self.indices = np.concatenate((tasks[id], self.indices), axis=None)\n",
        "           self.indices = np.arange(len(self.indices))\n",
        "        self.dataset = Subset(dataset, self.original_indices)\n",
        "        self.original2task = { self.indices[i]  : offset + i for i in range(0,  len(self.indices) ) } # remapping degli indici con chiavi i valori degli indici del del task\n",
        "        #self.original2task = self.dictmap(self.indices,offset)\n",
        "        self.task2original = dict({ (val, key) for (key, val) in self.original2task.items() }) # remapping degli indici con chiavi i valori degli indici del del task\n",
        "        \n",
        "  def __getitem__(self, idx):\n",
        "        (x, y) = self.dataset[idx]\n",
        "        return (x, self.original2task[y])\n",
        "\n",
        "  def __len__(self):\n",
        "        return len(self.original_indices)\n",
        "\n",
        "  def dictmap(self,indices,offset):\n",
        "      original2task={}\n",
        "      idx = np.arange(len(indices))\n",
        "      print(idx)\n",
        "      idx_tmp = np.arange(len(indices))\n",
        "      for i in range(0,len(idx)):\n",
        "        if (idx[i]+offset) in indices:\n",
        "          original2task[idx[i]+offset] = (idx[i] + offset)\n",
        "          indices  = np.delete(indices, np.argwhere(indices == (idx[i]+offset)))\n",
        "          idx_tmp  = np.delete(idx_tmp,np.argwhere(idx_tmp == (idx[i])))     \n",
        "      for i in range(0,len(indices)):\n",
        "          original2task[indices[i]]=idx_tmp[i] + offset   \n",
        "      return original2task\n",
        "\n",
        "\n",
        "def task_dss_replay(tasks,ds,offset_change=True): # aggiunto check su offset in modo tale da non cambaire offset ai task\n",
        "    task_dss = []\n",
        "    offset = 0\n",
        "    for i in range(0,len(tasks)) :\n",
        "      print(offset)\n",
        "      tmp = Filtered_Dataset_Replay(ds, tasks[i], tasks, i, offset)\n",
        "      task_dss.append(tmp)\n",
        "      if offset_change:\n",
        "          offset += len(tasks[i])\n",
        "      else :\n",
        "        offset = 0    \n",
        "    return task_dss  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiIqtZueNLln",
        "outputId": "74ac6c36-79c8-4aa6-fd84-c6a4cad9f7fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tasks = idx_tasks(5,ds_train,rand=False) \n",
        "task_train_dss_replay = task_dss_replay(tasks, ds_train,offset_change=False) \n",
        "task_test_dss = task_dss(tasks, ds_test,offset_change=False) \n",
        "task_train_dls = [DataLoader(ds,batch_size=16,shuffle=True,num_workers=4) for ds in task_train_dss_replay]\n",
        "task_test_dls = [DataLoader(ds, batch_size=16,shuffle=False,num_workers=4) for ds in task_test_dss]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmrTLby5-Yqo",
        "outputId": "287ea577-9175-4e96-f457-071a409f32b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "task_train_dss_replay[3].original2task\n",
        "#task_train_dss_replay[3].indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip8lLYDPJhGv",
        "outputId": "fc2bd859-84e6-4cc0-b0b0-e0d12e0ce030",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Training_Agnostic\n",
        "tasks = idx_tasks(5,ds_train,rand=False) \n",
        "task_train_dss_replay = task_dss_replay(tasks, ds_train,offset_change=False) \n",
        "task_test_dss = task_dss(tasks, ds_test,offset_change=False) \n",
        "task_train_dls = [DataLoader(ds,batch_size=16,shuffle=True,num_workers=4) for ds in task_train_dss_replay]\n",
        "task_test_dls = [DataLoader(ds, batch_size=16,shuffle=False,num_workers=4) for ds in task_test_dss]\n",
        "\n",
        "trained_net_agnostic,df_table_agn_agn,forgetting = continual_table(tasks,task_train_dls,task_test_dls,task_test_dss,agnostic_train=True,agnsotic_test=True)\n",
        "trained_net_agnostic,df_table_agn_aw,forgetting = continual_table(tasks,task_train_dls,task_test_dls,task_test_dss,agnostic_train=True,agnsotic_test=False)\n",
        "\n",
        "print(df_table_agn_agn) \n",
        "print(df_table_agn_aw)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=16384, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "Tempo dell'epoca  0 uguale a:  5.743764379003551 sec\n",
            "Tempo dell'epoca  1 uguale a:  5.652125218002766 sec\n",
            "Tempo dell'epoca  2 uguale a:  5.6669350939992 sec\n",
            "Tempo dell'epoca  3 uguale a:  5.647960206999414 sec\n",
            "Tempo dell'epoca  4 uguale a:  5.687311495999893 sec\n",
            "Tempo dell'epoca  5 uguale a:  5.78863115599961 sec\n",
            "Tempo dell'epoca  6 uguale a:  5.785586581998359 sec\n",
            "Tempo dell'epoca  7 uguale a:  5.559756542999821 sec\n",
            "Tempo dell'epoca  8 uguale a:  5.629598997998983 sec\n",
            "Tempo dell'epoca  9 uguale a:  5.663538977998542 sec\n",
            "Tempo dell'epoca  10 uguale a:  5.607695661001344 sec\n",
            "Tempo dell'epoca  11 uguale a:  5.593195700999786 sec\n",
            "Tempo dell'epoca  12 uguale a:  5.588890950002678 sec\n",
            "Tempo dell'epoca  13 uguale a:  5.670410460999847 sec\n",
            "Tempo dell'epoca  14 uguale a:  5.714495416999853 sec\n",
            "Tempo dell'epoca  15 uguale a:  5.674728777998098 sec\n",
            "Tempo dell'epoca  16 uguale a:  5.66371589299888 sec\n",
            "Tempo dell'epoca  17 uguale a:  5.609099708999565 sec\n",
            "Tempo dell'epoca  18 uguale a:  5.657253663001029 sec\n",
            "Tempo dell'epoca  19 uguale a:  5.65740815800018 sec\n",
            "ALLENAMENTO FINITO\n",
            "################################\n",
            "Accuracy of the network : 94 %\n",
            "TASK  0\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=16384, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (task0_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            ")\n",
            "Tempo dell'epoca  0 uguale a:  5.987929203998647 sec\n",
            "Tempo dell'epoca  1 uguale a:  5.888261105999845 sec\n",
            "Tempo dell'epoca  2 uguale a:  5.980992389002495 sec\n",
            "Tempo dell'epoca  3 uguale a:  5.975428469002509 sec\n",
            "Tempo dell'epoca  4 uguale a:  5.998974850001105 sec\n",
            "Tempo dell'epoca  5 uguale a:  5.945555598002102 sec\n",
            "Tempo dell'epoca  6 uguale a:  5.941280860999541 sec\n",
            "Tempo dell'epoca  7 uguale a:  5.944461248996959 sec\n",
            "Tempo dell'epoca  8 uguale a:  5.903728976998536 sec\n",
            "Tempo dell'epoca  9 uguale a:  5.9422701059993415 sec\n",
            "Tempo dell'epoca  10 uguale a:  5.939117334000912 sec\n",
            "Tempo dell'epoca  11 uguale a:  5.96417534399734 sec\n",
            "Tempo dell'epoca  12 uguale a:  5.881365631998051 sec\n",
            "Tempo dell'epoca  13 uguale a:  5.871618296001543 sec\n",
            "Tempo dell'epoca  14 uguale a:  5.892979721997108 sec\n",
            "Tempo dell'epoca  15 uguale a:  5.909533529000328 sec\n",
            "Tempo dell'epoca  16 uguale a:  5.962684355003148 sec\n",
            "Tempo dell'epoca  17 uguale a:  5.924410766998335 sec\n",
            "Tempo dell'epoca  18 uguale a:  5.8835001079969516 sec\n",
            "Tempo dell'epoca  19 uguale a:  5.98798316200191 sec\n",
            "ALLENAMENTO FINITO\n",
            "################################\n",
            "Accuracy of the network : 85 %\n",
            "TASK  1\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=16384, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (task0_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            "  (task1_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            ")\n",
            "Tempo dell'epoca  0 uguale a:  6.128691083999001 sec\n",
            "Tempo dell'epoca  1 uguale a:  6.1398283210000955 sec\n",
            "Tempo dell'epoca  2 uguale a:  6.161587694001355 sec\n",
            "Tempo dell'epoca  3 uguale a:  6.132747098999971 sec\n",
            "Tempo dell'epoca  4 uguale a:  6.1629936909994285 sec\n",
            "Tempo dell'epoca  5 uguale a:  6.1163743780016375 sec\n",
            "Tempo dell'epoca  6 uguale a:  6.147785967001255 sec\n",
            "Tempo dell'epoca  7 uguale a:  6.247791040001175 sec\n",
            "Tempo dell'epoca  8 uguale a:  6.274884258000384 sec\n",
            "Tempo dell'epoca  9 uguale a:  6.319609902999218 sec\n",
            "Tempo dell'epoca  10 uguale a:  6.2814294769996195 sec\n",
            "Tempo dell'epoca  11 uguale a:  6.324476035999396 sec\n",
            "Tempo dell'epoca  12 uguale a:  6.351885980999214 sec\n",
            "Tempo dell'epoca  13 uguale a:  6.357317784997576 sec\n",
            "Tempo dell'epoca  14 uguale a:  6.316655303999141 sec\n",
            "Tempo dell'epoca  15 uguale a:  6.318190035002772 sec\n",
            "Tempo dell'epoca  16 uguale a:  6.426913560000685 sec\n",
            "Tempo dell'epoca  17 uguale a:  6.583790145999956 sec\n",
            "Tempo dell'epoca  18 uguale a:  6.383996454998851 sec\n",
            "Tempo dell'epoca  19 uguale a:  6.497502892998455 sec\n",
            "ALLENAMENTO FINITO\n",
            "################################\n",
            "Accuracy of the network : 91 %\n",
            "TASK  2\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=16384, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (task0_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            "  (task1_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            "  (task2_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            ")\n",
            "Tempo dell'epoca  0 uguale a:  6.742059850999794 sec\n",
            "Tempo dell'epoca  1 uguale a:  6.645072648996575 sec\n",
            "Tempo dell'epoca  2 uguale a:  6.7371473720013455 sec\n",
            "Tempo dell'epoca  3 uguale a:  6.741201107997767 sec\n",
            "Tempo dell'epoca  4 uguale a:  6.5217556999996305 sec\n",
            "Tempo dell'epoca  5 uguale a:  6.6607631759979995 sec\n",
            "Tempo dell'epoca  6 uguale a:  6.694097023999348 sec\n",
            "Tempo dell'epoca  7 uguale a:  6.622330006000993 sec\n",
            "Tempo dell'epoca  8 uguale a:  6.752236244003143 sec\n",
            "Tempo dell'epoca  9 uguale a:  6.659713075001491 sec\n",
            "Tempo dell'epoca  10 uguale a:  6.635635776998242 sec\n",
            "Tempo dell'epoca  11 uguale a:  6.726228652998543 sec\n",
            "Tempo dell'epoca  12 uguale a:  6.6843969429974095 sec\n",
            "Tempo dell'epoca  13 uguale a:  6.715106894997007 sec\n",
            "Tempo dell'epoca  14 uguale a:  6.670499346997531 sec\n",
            "Tempo dell'epoca  15 uguale a:  6.692835448000551 sec\n",
            "Tempo dell'epoca  16 uguale a:  6.629830899997614 sec\n",
            "Tempo dell'epoca  17 uguale a:  6.659538215000794 sec\n",
            "Tempo dell'epoca  18 uguale a:  6.639749997000763 sec\n",
            "Tempo dell'epoca  19 uguale a:  6.616792161003104 sec\n",
            "ALLENAMENTO FINITO\n",
            "################################\n",
            "Accuracy of the network : 97 %\n",
            "TASK  3\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=16384, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (task0_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            "  (task1_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            "  (task2_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            "  (task3_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            ")\n",
            "Tempo dell'epoca  0 uguale a:  7.031893847997708 sec\n",
            "Tempo dell'epoca  1 uguale a:  6.962750820002839 sec\n",
            "Tempo dell'epoca  2 uguale a:  6.823986743002024 sec\n",
            "Tempo dell'epoca  3 uguale a:  6.949824240000453 sec\n",
            "Tempo dell'epoca  4 uguale a:  6.902315250998072 sec\n",
            "Tempo dell'epoca  5 uguale a:  6.935922512999241 sec\n",
            "Tempo dell'epoca  6 uguale a:  7.003365131000464 sec\n",
            "Tempo dell'epoca  7 uguale a:  6.913633883999864 sec\n",
            "Tempo dell'epoca  8 uguale a:  6.782534123001824 sec\n",
            "Tempo dell'epoca  9 uguale a:  6.918907677998504 sec\n",
            "Tempo dell'epoca  10 uguale a:  6.815900399000384 sec\n",
            "Tempo dell'epoca  11 uguale a:  6.8362758939983905 sec\n",
            "Tempo dell'epoca  12 uguale a:  6.814764489001391 sec\n",
            "Tempo dell'epoca  13 uguale a:  6.884303922000981 sec\n",
            "Tempo dell'epoca  14 uguale a:  6.824291884000559 sec\n",
            "Tempo dell'epoca  15 uguale a:  6.846554208997986 sec\n",
            "Tempo dell'epoca  16 uguale a:  6.81447389800087 sec\n",
            "Tempo dell'epoca  17 uguale a:  6.892457145000662 sec\n",
            "Tempo dell'epoca  18 uguale a:  6.896532003000175 sec\n",
            "Tempo dell'epoca  19 uguale a:  6.837809017000836 sec\n",
            "ALLENAMENTO FINITO\n",
            "################################\n",
            "Accuracy of the network : 95 %\n",
            "TASK  4\n",
            "[0, 1, 2, 3, 4]\n",
            "Accuracy of the network : 4 %\n",
            "Accuracy of the network : 6 %\n",
            "Accuracy of the network : 22 %\n",
            "Accuracy of the network : 46 %\n",
            "Accuracy of the network : 95 %\n",
            "Accuracy Precedente: 92.95 Accuracy Successiva: 35.19\n",
            "Forgetting: 57.760000000000005\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=16384, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "Tempo dell'epoca  0 uguale a:  5.873425608002435 sec\n",
            "Tempo dell'epoca  1 uguale a:  5.859396764997655 sec\n",
            "Tempo dell'epoca  2 uguale a:  5.944885123000859 sec\n",
            "Tempo dell'epoca  3 uguale a:  5.893422493998514 sec\n",
            "Tempo dell'epoca  4 uguale a:  5.778926322996995 sec\n",
            "Tempo dell'epoca  5 uguale a:  5.759799395997106 sec\n",
            "Tempo dell'epoca  6 uguale a:  5.786962162997952 sec\n",
            "Tempo dell'epoca  7 uguale a:  5.872565379999287 sec\n",
            "Tempo dell'epoca  8 uguale a:  5.85735086600107 sec\n",
            "Tempo dell'epoca  9 uguale a:  5.836388545001682 sec\n",
            "Tempo dell'epoca  10 uguale a:  5.950919504000922 sec\n",
            "Tempo dell'epoca  11 uguale a:  5.786311944997578 sec\n",
            "Tempo dell'epoca  12 uguale a:  5.80890490100137 sec\n",
            "Tempo dell'epoca  13 uguale a:  5.841413194997585 sec\n",
            "Tempo dell'epoca  14 uguale a:  5.812126946002536 sec\n",
            "Tempo dell'epoca  15 uguale a:  5.738262506998581 sec\n",
            "Tempo dell'epoca  16 uguale a:  5.821817568998085 sec\n",
            "Tempo dell'epoca  17 uguale a:  5.860324971999944 sec\n",
            "Tempo dell'epoca  18 uguale a:  5.7497681559980265 sec\n",
            "Tempo dell'epoca  19 uguale a:  5.8036600060004275 sec\n",
            "ALLENAMENTO FINITO\n",
            "################################\n",
            "Accuracy of the network : 95 %\n",
            "TASK  0\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=16384, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (task0_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            ")\n",
            "Tempo dell'epoca  0 uguale a:  6.000383918999432 sec\n",
            "Tempo dell'epoca  1 uguale a:  6.075670402999094 sec\n",
            "Tempo dell'epoca  2 uguale a:  6.103018524998333 sec\n",
            "Tempo dell'epoca  3 uguale a:  6.0851842160009255 sec\n",
            "Tempo dell'epoca  4 uguale a:  6.051785532999929 sec\n",
            "Tempo dell'epoca  5 uguale a:  6.041175459999067 sec\n",
            "Tempo dell'epoca  6 uguale a:  6.089140297000995 sec\n",
            "Tempo dell'epoca  7 uguale a:  6.138123141001415 sec\n",
            "Tempo dell'epoca  8 uguale a:  6.171537783997337 sec\n",
            "Tempo dell'epoca  9 uguale a:  6.013848329999746 sec\n",
            "Tempo dell'epoca  10 uguale a:  6.086707867998484 sec\n",
            "Tempo dell'epoca  11 uguale a:  6.135545191998972 sec\n",
            "Tempo dell'epoca  12 uguale a:  6.071468276997621 sec\n",
            "Tempo dell'epoca  13 uguale a:  6.106853098001011 sec\n",
            "Tempo dell'epoca  14 uguale a:  6.156768116001331 sec\n",
            "Tempo dell'epoca  15 uguale a:  6.108898907001276 sec\n",
            "Tempo dell'epoca  16 uguale a:  6.142675973998848 sec\n",
            "Tempo dell'epoca  17 uguale a:  6.059058318001917 sec\n",
            "Tempo dell'epoca  18 uguale a:  6.138857945999916 sec\n",
            "Tempo dell'epoca  19 uguale a:  6.087149642997247 sec\n",
            "ALLENAMENTO FINITO\n",
            "################################\n",
            "Accuracy of the network : 84 %\n",
            "TASK  1\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=16384, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (task0_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            "  (task1_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            ")\n",
            "Tempo dell'epoca  0 uguale a:  6.306197128000349 sec\n",
            "Tempo dell'epoca  1 uguale a:  6.418006919997424 sec\n",
            "Tempo dell'epoca  2 uguale a:  6.343527780998556 sec\n",
            "Tempo dell'epoca  3 uguale a:  6.336183059000177 sec\n",
            "Tempo dell'epoca  4 uguale a:  6.356946407999203 sec\n",
            "Tempo dell'epoca  5 uguale a:  6.339365455998632 sec\n",
            "Tempo dell'epoca  6 uguale a:  6.412990217999322 sec\n",
            "Tempo dell'epoca  7 uguale a:  6.323071129001619 sec\n",
            "Tempo dell'epoca  8 uguale a:  6.384107812998991 sec\n",
            "Tempo dell'epoca  9 uguale a:  6.3940863629977684 sec\n",
            "Tempo dell'epoca  10 uguale a:  6.290868279000279 sec\n",
            "Tempo dell'epoca  11 uguale a:  6.3876257490010175 sec\n",
            "Tempo dell'epoca  12 uguale a:  6.417059146999236 sec\n",
            "Tempo dell'epoca  13 uguale a:  6.536510850000923 sec\n",
            "Tempo dell'epoca  14 uguale a:  6.38389297699905 sec\n",
            "Tempo dell'epoca  15 uguale a:  6.228595844000665 sec\n",
            "Tempo dell'epoca  16 uguale a:  6.408321858998534 sec\n",
            "Tempo dell'epoca  17 uguale a:  6.427180755999871 sec\n",
            "Tempo dell'epoca  18 uguale a:  6.339342077000765 sec\n",
            "Tempo dell'epoca  19 uguale a:  6.316199046999827 sec\n",
            "ALLENAMENTO FINITO\n",
            "################################\n",
            "Accuracy of the network : 92 %\n",
            "TASK  2\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=16384, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (task0_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            "  (task1_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            "  (task2_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            ")\n",
            "Tempo dell'epoca  0 uguale a:  6.637006657998427 sec\n",
            "Tempo dell'epoca  1 uguale a:  6.62401918100295 sec\n",
            "Tempo dell'epoca  2 uguale a:  6.613530359998549 sec\n",
            "Tempo dell'epoca  3 uguale a:  6.648998003998713 sec\n",
            "Tempo dell'epoca  4 uguale a:  6.56442446499932 sec\n",
            "Tempo dell'epoca  5 uguale a:  6.613569286000711 sec\n",
            "Tempo dell'epoca  6 uguale a:  6.620421602998249 sec\n",
            "Tempo dell'epoca  7 uguale a:  6.591171124000539 sec\n",
            "Tempo dell'epoca  8 uguale a:  6.601590351001505 sec\n",
            "Tempo dell'epoca  9 uguale a:  6.614785436999227 sec\n",
            "Tempo dell'epoca  10 uguale a:  6.570224122999207 sec\n",
            "Tempo dell'epoca  11 uguale a:  6.6532694779998565 sec\n",
            "Tempo dell'epoca  12 uguale a:  6.519696643001225 sec\n",
            "Tempo dell'epoca  13 uguale a:  6.589850744003343 sec\n",
            "Tempo dell'epoca  14 uguale a:  6.544892619000166 sec\n",
            "Tempo dell'epoca  15 uguale a:  6.543240120001428 sec\n",
            "Tempo dell'epoca  16 uguale a:  6.543019624001317 sec\n",
            "Tempo dell'epoca  17 uguale a:  6.600434715001029 sec\n",
            "Tempo dell'epoca  18 uguale a:  6.609358396999596 sec\n",
            "Tempo dell'epoca  19 uguale a:  6.5748219350025465 sec\n",
            "ALLENAMENTO FINITO\n",
            "################################\n",
            "Accuracy of the network : 97 %\n",
            "TASK  3\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=16384, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (task0_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            "  (task1_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            "  (task2_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            "  (task3_fc): Linear(in_features=84, out_features=2, bias=True)\n",
            ")\n",
            "Tempo dell'epoca  0 uguale a:  6.915604608002468 sec\n",
            "Tempo dell'epoca  1 uguale a:  6.845596565999585 sec\n",
            "Tempo dell'epoca  2 uguale a:  6.894186595996871 sec\n",
            "Tempo dell'epoca  3 uguale a:  6.910733090000576 sec\n",
            "Tempo dell'epoca  4 uguale a:  6.92210685900136 sec\n",
            "Tempo dell'epoca  5 uguale a:  6.9117759830005525 sec\n",
            "Tempo dell'epoca  6 uguale a:  6.839352076000068 sec\n",
            "Tempo dell'epoca  7 uguale a:  6.907554114997765 sec\n",
            "Tempo dell'epoca  8 uguale a:  6.938165109000693 sec\n",
            "Tempo dell'epoca  9 uguale a:  6.799615722000453 sec\n",
            "Tempo dell'epoca  10 uguale a:  6.85006558799796 sec\n",
            "Tempo dell'epoca  11 uguale a:  6.9679787140012195 sec\n",
            "Tempo dell'epoca  12 uguale a:  6.812430264002614 sec\n",
            "Tempo dell'epoca  13 uguale a:  6.838300217998039 sec\n",
            "Tempo dell'epoca  14 uguale a:  6.917500696999923 sec\n",
            "Tempo dell'epoca  15 uguale a:  6.7833660899996175 sec\n",
            "Tempo dell'epoca  16 uguale a:  6.940870399001142 sec\n",
            "Tempo dell'epoca  17 uguale a:  6.917040705000545 sec\n",
            "Tempo dell'epoca  18 uguale a:  6.833964928999194 sec\n",
            "Tempo dell'epoca  19 uguale a:  7.138686804002646 sec\n",
            "ALLENAMENTO FINITO\n",
            "################################\n",
            "Accuracy of the network : 96 %\n",
            "TASK  4\n",
            "[0, 1, 2, 3, 4]\n",
            "Accuracy of the network : 91 %\n",
            "Accuracy of the network : 71 %\n",
            "Accuracy of the network : 75 %\n",
            "Accuracy of the network : 89 %\n",
            "Accuracy of the network : 96 %\n",
            "Accuracy Precedente: 93.27 Accuracy Successiva: 84.72\n",
            "Forgetting: 8.549999999999997\n",
            "   first_training  last_training\n",
            "0           94.70           4.50\n",
            "1           85.50           6.50\n",
            "2           91.80          22.50\n",
            "3           97.20          46.90\n",
            "4           95.55          95.55\n",
            "   first_training  last_training\n",
            "0           95.80           91.3\n",
            "1           84.50           71.0\n",
            "2           92.35           75.4\n",
            "3           97.50           89.7\n",
            "4           96.20           96.2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}